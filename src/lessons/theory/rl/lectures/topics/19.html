<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" type="text/css" href="../../../css/page.css">
		<link rel="stylesheet" type="text/css" href="../../../css/katex.css">
		<title></title>
	</head>
	<body>
		<div class="page">
			<div class="sidebar">
				<a id="nextPage">
					<img src="../../../css/icons/forward.svg" title="Далее">
				</a>
				<a id="prevPage">
					<img src="../../../css/icons/backward.svg" title="Назад">
				</a>
				<a href="index.html">
					<img src="../../../css/icons/submenu.svg" title="Подменю">
				</a>
				<a href="../../../index.html">
					<img src="../../../css/icons/menu.svg" title="Главное меню">
				</a>
				<a href="https://t.me/quessentry">
					<img src="../../../css/icons/tg.svg" class="icon" title="Связь со мной">
				</a>
			</div>
			<div class="elements">
				<div class="topic">
					<div class="num">
						<p>19</p>
					</div>
					<div class="title">
						<p>Марковские цепи. Стационарность и эргодичность. Алгоритм Метрополиса-Гастингса</p>
					</div>
				</div>
				<div class="content">
					<p>Марковская цепь — это математическая модель, описывающая последовательность событий, где вероятность каждого события зависит только от состояния, достигнутого в предыдущем событии. Формально, марковская цепь задается тройкой $(S, P, \mu)$, где:</p>
					<ul>
						<li>$S$ — конечное или счетное множество состояний;</li>
						<li>$P: S \times S \rightarrow [0,1]$ — матрица переходных вероятностей, где $P_{ij}$ обозначает вероятность перехода из состояния $i$ в состояние $j$;</li>
						<li>$\mu: S \rightarrow [0,1]$ — начальное распределение вероятностей на состояниях.</li>
					</ul>
					<p>Свойство Маркова выражается следующим образом:</p>
					<p class="equation">$\mathbb{P}(X_{n+1} = j \mid X_n = i_n, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = \mathbb{P}(X_{n+1} = j \mid X_n = i_n) = P_{ij}$.</p>
					<p class="sign">Стационарность</p>
					<p>Стационарное распределение $\pi(x)$ марковской цепи — это распределение, которое остается неизменным при переходе по цепи:</p>
					<p class="equation">$\pi_j = \sum\limits_{i \in S} \pi_i P_{ij} \ \ \ \forall j \in S$.</p>
					<p>В матричной форме это можно записать так: $\pi = \pi P$, где $\pi$ — вектор-строка стационарного распределения. То есть $\pi$ это собственный вектор матрицы. Стационарное распределение интерпретируется как предельное распределение, к которому стремится цепь при больших $t$, если оно существует.</p>
					<p class="sign">Эргодичность</p>
					<p>Марковская цепь называется эргодической, если она имеет единственное стационарное распределение $\pi$, и для любого начального распределения $\mu$ выполняется:</p>
					<p class="equation">$\lim\limits_{n \to \infty} \mu P^n = \pi$.</p>
					<p>Эргодичность гарантирует, что независимо от начального состояния, система сходится к одному и тому же стационарному распределению.</p>
					<p>Условия эргодичности</p>
					<ol>
						<li>Ирредуцируемость: можно попасть из любого состояния $x$ в любые другие $x'$ за конечное число шагов с ненулевой вероятностью.</li>
						<li>Апериодичность: цепь не зацикливается в фиксированных интервалах времени (нет строгой периодичности).</li>
						<li>Положительная возвратность: состояние имеет конечное среднее время возврата.</li>
					</ol>
					<p class="sign">Алгоритм Метрополиса-Гастингса</p>
					<p>Алгоритм Метрополиса-Гастингса — это метод генерации выборки из сложного распределения $\pi$ с использованием более простого предложенного распределения $Q$.</p>
					<ol>
						<li>Инициализация: выбор начального состояния $X_0$.</li>
						<li>Итерационный процесс:
							<ul>
								<li>на шаге $n$ предлагается новое состояние Y из распределения $Q(Y \mid X_n)$;</li>
								<li>вычислить вероятность принятия $\alpha(X_n, Y)$:
									<p class="equation">$\alpha(X_n, Y) = \min{\bigg(1, \dfrac{\pi(Y)Q(X_n \mid Y)}{\pi(X_n)Q(Y \mid X_n)}\bigg)}$;</p>
								</li>
								<li>с вероятностью $\alpha(X_n, Y)$ принять новое состояние: $X_{n+1} = Y$, иначе оставить текущее состояние $X_{n+1} = X_n$.</li>
								<li></li>
							</ul>
						</li>
						<p>Алгоритм гарантирует, что последовательность состояний $\{X_n\}$ сходится к стационарному распределению $\pi$, если цепь апериодична и неприводима.</p>
					</ol>
					<p class="sign">Пример:</p>
					<p>Представим, что мы играем в игру, где мы перемещаемся между разными состояниями (например, комнатами в доме). Каждый раз мы выбираем, куда пойти дальше, но наш выбор зависит только от того, где мы сейчас находимся, а не от того, как мы сюда попали. Это и есть марковская цепь — модель, где будущее зависит только от настоящего, а не от прошлого.</p>
					<p>Пример: если мы в комнате $A$, то с вероятностью $50\%$ мы пойдем в комнату $B$, а с вероятностью $50\%$ останемся в $A$. Это называется вероятностью перехода.</p>
					<p>Теперь представим, что мы играем в эту игру очень долго. В какой-то момент мы заметим, что вероятность оказаться в каждой комнате перестает меняться. Например, мы будем находиться в комнате $A$ с вероятностью $30\%$, а в комнате $B$ — с вероятностью $70\%$, и эти числа больше не изменяются. Это и есть стационарное распределение — состояние, когда система "устаканивается" и вероятности перестают меняться.</p>
					<p>Эргодичность — это свойство марковской цепи, которое гарантирует, что независимо от того, с какой комнаты мы начали, через достаточно долгое время мы будем находиться в каждой комнате с одними и теми же вероятностями (теми самыми, которые задает стационарное распределение). То есть система "забывает" начальное состояние и выходит на один и тот же режим.</p>
					<p class="sign">Алгоритм Метрополиса-Хастингса</p>
					<p>Этот алгоритм помогает нам генерировать выборку из сложного распределения, которое мы не можем посчитать напрямую. Например, представим, что у нас есть сложная карта местности, и нам нужно случайным образом выбирать точки на ней, но так, чтобы чаще попадать в "интересные" места (например, горы, а не равнины).</p>
					<ol>
						<li>Начинаем с какой-то случайной точки.</li>
						<li>Предлагаем новую точку (например, делаете случайный шаг в любом направлении).</li>
						<li>Решаем, перейти ли в эту новую точку или остаться на месте. Это решение зависит от того, насколько новая точка "интереснее" текущей: если новая точка лучше, мы переходим туда; если хуже, мы можем перейти туда с некоторой вероятностью или остаться на месте.</li>
						<li>Повторяем процесс много раз.</li>
					</ol>
					<p>В результате, после многих шагов, мы получим набор точек, которые будут соответствовать "интересным" местам на карте. Это и есть выборка из сложного распределения.</p>
				</div>
			</div>
		</div>
	</body>
	<script type="text/javascript" src="../../../js/katex.js"></script>
	<script type="text/javascript" src="../../../js/contrib/auto-render.js"></script>
	<script type="text/javascript" src="../../../js/render.js"></script>
	<script type="text/javascript" src="../../../js/display.js"></script>
	<script type="text/javascript" src="../../../js/navigate.js"></script>
</html>