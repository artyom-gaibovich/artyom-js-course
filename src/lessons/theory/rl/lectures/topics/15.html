<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" type="text/css" href="../../../css/page.css">
		<link rel="stylesheet" type="text/css" href="../../../css/katex.css">
		<title></title>
	</head>
	<body>
		<div class="page">
			<div class="sidebar">
				<a id="nextPage">
					<img src="../../../css/icons/forward.svg" title="Далее">
				</a>
				<a id="prevPage">
					<img src="../../../css/icons/backward.svg" title="Назад">
				</a>
				<a href="index.html">
					<img src="../../../css/icons/submenu.svg" title="Подменю">
				</a>
				<a href="../../../index.html">
					<img src="../../../css/icons/menu.svg" title="Главное меню">
				</a>
				<a href="https://t.me/quessentry">
					<img src="../../../css/icons/tg.svg" class="icon" title="Связь со мной">
				</a>
			</div>
			<div class="elements">
				<div class="topic">
					<div class="num">
						<p>15</p>
					</div>
					<div class="title">
						<p>МБ. Томпсон семплинг.</p>
					</div>
				</div>
				<div class="content">
					<p class="redline">Томпсон семплинг — это байесовский подход к решению задачи многорукого бандита. Он основан на идее использования апостериорных распределений для выбора действий. Основные шаги алгоритма:</p>
					<ol class="roman">
						<li>Инициализация априорных распределений: для каждой ручки $i$ задаётся априорное распределение на параметры распределения наград $P_i$.</li>
						<li>На каждом шаге $t$ для каждой ручки $i$ сэмплируется значение параметра $\theta_i$ из текущего апостериорного распределения: $\theta_i \sim \text{Posterior}$.</li>
						<li>Выбираем автомат с наибольшим мат. ожиданием согласно выпавшим $\theta_i$.</li>
						<li>После получения вознаграждения параметры апостериорного распределения обновляются</li>
						<li>Шаги 2-4 повторяются для каждого шага $t$.</li>
					</ol>
					<p>Идея в том, что для автоматов, которые мы пробовали часто, дисперсия апостериорного распределения будет маленькой и сэмпл почти всегда в точности будет равен текущей оценке $Q$-функции. Для автоматов, которые мы пробовали редко, дисперсия будет большая, что заставит нас их еще использовать.</p>
					<p>Проще:</p>
					<ul>
						<li>начинаем с предположений о том, насколько каждый автомат может быть выгодным. Это наше априорное распределение (начальное предположение);</li>
						<li>на каждом шаге "представляем" (сэмплируем) возможные значения выигрышей для каждого автомата, основываясь на текущих данных;</li>
						<li>выбираете автомат, который в нашем "представлении" выглядит самым выгодным;</li>
						<li>после того как мы сыграли на выбранном автомате, мы обновляем свои представления о нём (что есть апостериорное распределение).</li>
					</ul>
					<p class="sign">Пример с монеткой</p>
					<ul>
						<li>Инициализация: $\alpha_1 = \alpha_2 = 1$, $\beta_1=\beta_2=1$.</li>
						<li>Шаг 1
							<ul>
								<li>сэмплируем $\hat{\theta}_1 \sim \text{Beta}(1,1)$ и $\hat{\theta}_2 \sim \text{Beta}(1,1)$;</li>
								<li>предположим, $\hat{\theta}_1 = 0.6$, $\hat{\theta}_2 = 0.4$;</li>
								<li>выбираем руку 1 ($a_1=1)$;</li>
								<li>показываем рекламу 1 и получаем $r_1 = 1$ (клик);</li>
								<li>обновляем параметры: $\alpha_{a_t} \leftarrow \alpha_{a_t} + r_t$, $\beta{a_t} \leftarrow \beta{a_t} + (1-r_t)$, получаем $\alpha_1=2$, $\beta_1=1$.</li>
							</ul>
						</li>
						<li>Шаг 2
							<ul>
								<li>сэмплируем $\hat{\theta}_1 \sim \text{Beta}(2,1)$ и $\hat{\theta}_2 \sim \text{Beta}(1,1)$;</li>
								<li>предположим, $\hat{\theta}_1 = 0.7$, $\hat{\theta}_2 = 0.5$;</li>
								<li>выбираем руку 1 ($a_2=1)$;</li>
								<li>показываем рекламу 1 и получаем $r_1 = 0$ (нет клика);</li>
								<li>обновляем параметры: $\alpha_{a_t} \leftarrow \alpha_{a_t} + r_t$, $\beta{a_t} \leftarrow \beta{a_t} + (1-r_t)$, получаем $\alpha_1=2$, $\beta_1=2$.</li>
							</ul>
						</li>
						<li>Шаг 3
							<ul>
								<li>сэмплируем $\hat{\theta}_1 \sim \text{Beta}(2,2)$ и $\hat{\theta}_2 \sim \text{Beta}(1,1)$;</li>
								<li>предположим, $\hat{\theta}_1 = 0.4$, $\hat{\theta}_2 = 0.6$;</li>
								<li>выбираем руку 2 ($a_3=2)$;</li>
								<li>показываем рекламу 2 и получаем $r_1 = 1$ (клик);</li>
								<li>обновляем параметры: $\alpha_{a_t} \leftarrow \alpha_{a_t} + r_t$, $\beta{a_t} \leftarrow \beta{a_t} + (1-r_t)$, получаем $\alpha_2=2$, $\beta_2=1$.</li>
							</ul>
						</li>
						<p>Процесс продолжается, и с каждым шагом апостериорные распределения становятся более точными, что позволяет агенту лучше оценивать вероятности успеха для каждой рекламы и принимать более обоснованные решения.</p>
					</ul>
				</div>
			</div>
		</div>
	</body>
	<script type="text/javascript" src="../../../js/katex.js"></script>
	<script type="text/javascript" src="../../../js/contrib/auto-render.js"></script>
	<script type="text/javascript" src="../../../js/render.js"></script>
	<script type="text/javascript" src="../../../js/display.js"></script>
	<script type="text/javascript" src="../../../js/navigate.js"></script>
</html>